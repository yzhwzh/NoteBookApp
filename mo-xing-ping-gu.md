# 模型评估

### 泛化能力

1. 为了评估机器学习算法的能力，必须给定其性能的衡量指标。
2. 有些情况下，很难决定衡量指标是什么：
   * 如：翻译任务中，应该衡量整个翻译结果的准确率，还是衡量每个单词翻译的准确率？
   * 如：密度估计任务中，很多模型都是隐式地表示概率分布。此时计算样本空间某个点的真实概率是不可行的，因此也就无法判断该点的概率估计的准确率。
3. 通常利用最小化训练误差来训练模型，但是真正关心的是测试误差。**因此通过测试误差来评估模型的泛化能力。**
   * **训练误差是模型在训练集的平均损失，其大小虽然有意义，但是本质上不重要。**
   * **测试误差是模型在测试集上的平均损失，反应了模型对未知测试数据集的预测能力。**
4. **模型对未知数据的预测能力称作模型的泛化能力，它是模型最重要的性质。**

   泛化误差可以反映模型的泛化能力：泛化误差越小，该模型越有效。

5. 假设训练集和测试集共同的、潜在的样本分布称作数据生成分布，记作 $$p_{data}(\mathbf{\vec x},y)$$。则泛化误差定义为模型的期望风险，即： $$R_{exp}(f)=\mathbb E[L(y, f(\mathbf{\vec x}))]=\int_{\mathcal{X \times Y}}L(y, f(\mathbf{\vec x}))p_{data}(\mathbf {\vec x},y)d \mathbf {\vec x}\; dy$$ 
   * 通常泛化误差是不可知的，因为无法获取联合概率分布 $$p_{data}(\mathbf{\vec x},y)$$ 以及无限的采样点。
   * 现实中通常利用测试误差评估模型的泛化能力。由于测试数据集是有限的，因此这种评估结果不完全准确。
6. 统计理论表明：如果训练集和测试集中的样本都是独立同分布产生的，则有 **模型的训练误差的期望等于模型的测试误差的期望** 。
7. 机器学习的“没有免费的午餐定理”表明：在所有可能的数据生成分布上，没有一个机器学习算法总是比其他的要好。
   * 该结论仅在考虑所有可能的数据分布时才成立。
   * **现实中特定任务的数据分布往往满足某类假设，从而可以设计在这类分布上效果更好的学习算法。**
   * 这意味着机器学习并不需要寻找一个通用的学习算法，而是寻找一个在关心的数据分布上效果最好的算法。
8. 正则化是对学习算法做的一个修改，这种修改趋向于降低泛化误差（而不是降低训练误差）。
   * 正则化是机器学习领域的中心问题之一。
   * **没有免费的午餐定理说明了没有最优的学习算法，因此也没有最优的正则化形式。**

### 过拟合、欠拟合

1. 当使用机器学习算法时，决定机器学习算法效果的两个因素：降低训练误差、缩小训练误差和测试误差的差距。

   这两个因素对应着机器学习中的两个主要挑战：欠拟合和过拟合。

2. 过拟合`overfitting`：**选择的模型包含的参数过多**，以至于该模型对于已知数据预测得很好，但是对于未知数据预测的很差，使得训练误差和测试误差之间的差距太大。
   * 过拟合的原因是：将训练样本本身的一些特点当作了所有潜在样本都具有的一般性质，这会造成泛化能力下降。
   * 过拟合无法避免，只能缓解。因为机器学习的问题通常是`NP`难甚至更难的，而有效的学习算法必然是在多项式时间内运行完成。如果可以避免过拟合，这就意味着构造性的证明了`P=NP` 。
3. 欠拟合`underfitting`：**选择的模型包含的参数太少，以至于该模型对已知数据都预测的很差**，使得训练误差较大。

   欠拟合的原因一般是学习能力低下造成的。

4. **通过调整模型的容量`capacity`可以缓解欠拟合和过拟合。**

#### 模型容量

1. **模型的容量是指其拟合各种函数的能力。**
   * **容量低的模型容易发生欠拟合，模型拟合能力太弱。**
   * **容量高的模型容易发生过拟合，模型拟合能力太强。**
2. 通过选择不同的假设空间可以改变模型的容量。

   模型的假设空间指的是：代表模型的函数集合。这也称作模型的表示容量`representational capacity`。

   由于额外的限制因素（比如优化算法的不完善），模型的有效容量`effective capacity`一般会小于模型的表示容量。

3. 通常在模型的假设空间中出最佳的函数是非常困难的优化问题，实际应用中只是挑选一个使得训练误差足够低的函数即可。
4. 统计学习理论提供了**量化模型容量**的方法，其中最出名的是**`VC`维理论**：**训练误差与泛化误差之间差异的上界随着模型容量增长而增长，随着训练样本增多而下降** 。
5. 虽然`VC` 维理论对于机器学习算法有很好的指导作用，但是它在深度学习很难应用。原因有二：
   * 边界太宽泛。
   * 难以确定深度学习的容量。由于深度学习模型的有效容量受限于优化算法，因此确定深度学习模型的容量特别困难。
6. 通常泛化误差是关于模型容量的 `U`形函数。随着模型容量增大：
   * 训练误差会下降直到逼近其最小值。
   * 泛化误差先减小后增大。
   * 泛化误差与训练误差的差值会增大。

![](.gitbook/assets/image%20%2817%29.png)

#### 缓解过拟合

1. 缓解过拟合的策略：

   * 正则化。
   * 数据集增强：通过人工规则产生虚假数据来创造更多的训练数据。
   * 噪声注入：包括输入噪声注入、输出噪声注入、权重噪声注入。将噪声分别注入到输入/输出/权重参数中。
   * 早停：当验证集上的误差没有进一步改善时，算法提前终止。

   > 具体内容参考深度学习《正则化》章节。

2. 正则化 ：基于结构化风险最小化（`SRM`）策略的实现，其中 $$J(f)$$ 为正则化项。

   在不同的问题中，正则化项可以有不同的形式：

   * 回归问题中，损失函数是平方损失，正则化项是参数向量的 $$L_2$$ 范数。
   * 贝叶斯估计中，正则化项对应于模型的先验概率 $$\log \frac{1}{g(\theta)}$$ 。

#### 缓解欠拟合

缓解欠拟合的策略：**选择一个模型容量更高的模型**

### 偏差方差分解

#### 点估计

1. 点估计：对参数 $$\theta$$ 的一个预测，记作 $$\hat \theta$$ ****。

   假设 $$\{x_1,x_2,\cdots,x_m\}$$ 为独立同分布的数据点，该分布由参数 $$\theta$$ 决定。则参数 $$\theta$$ 的点估计为某个函数： $$\hat\theta_m =g(x_1,x_2,\cdots,x_m)$$  

   注意：点估计的定义并不要求  返回一个接近真实值 $$\theta$$ 。

2. 根据频率学派的观点：
   * 真实参值 $$\theta$$ 是固定的，但是未知的。
   *  $$\hat\theta_m$$ 是数据点的函数。
   * 由于数据是随机采样的，因此 $$\hat\theta_m$$ 是个随机变量。

#### 偏差

1. 偏差定义为： $$bias(\hat\theta_m)=\mathbb E(\hat\theta_m)-\theta$$ ，期望作用在所有数据上。
   * 如果 $$bias(\hat\theta_m)=0$$  ，则称估计量 $$\hat\theta_m$$  是无偏的。
   * 如果 $$\lim_{m\rightarrow \infty}bias(\hat\theta_m)=0$$ ，则称估计量 $$\hat\theta_m$$ 是渐近无偏的。
2. 无偏估计并不一定是最好的估计。
3. 偏差的例子：
   * 一组服从均值为 $$\theta$$  的伯努利分布的独立同分布样本 $$\{x_1,x_2,\cdots,x_m\}$$  ： $$\hat\theta_m=\frac 1m\sum_{i=1}^{m}x_i$$  为 $$\theta$$ 的无偏估计。
   * 一组服从均值为 $$\mu$$ ，方差为 $$\sigma^{2}$$  的高斯分布的独立同分布样本 ：
     *  $$\hat\mu_m=\frac 1m\sum_{i=1}^{m}x_i$$ 为 $$\mu$$ 的无偏估计。
     *  $$\hat\sigma^{2}_m=\frac 1m\sum_{i=1}^{m}(x_i-\hat\mu_m)^{2}$$ 为 $$\sigma^{2}$$ 的有偏估计。因为 $$\mathbb E[\hat\sigma^{2}_m]=\frac{m-1}{m}\sigma^{2}$$ 
     *  $$\tilde\sigma^{2}_m=\frac {1}{m-1}\sum_{i=1}^{m}(x_i-\hat\mu_m)^{2}$$ 为 $$\sigma^{2}$$ 的无偏估计。

#### 一致性

1. 通常希望当数据集的大小 $$m$$ 增加时，点估计会收敛到对应参数的真实值。即： $$\text{plim}_{m\rightarrow \infty}\hat\theta_m=\theta$$ 表示依概率收敛。即对于任意的 $$\epsilon \gt 0$$ ，当 $$m\rightarrow \infty$$ 时，有： $$P(|\hat\theta_m -\theta|)\gt \epsilon \rightarrow 0$$ 
2. 上述条件也称做一致性。它保证了估计偏差会随着样本数量的增加而减少。
3. 渐近无偏不一定意味着一致性。

       如：在正态分布产生的数据集中，可以用 $$\hat\mu_m=x_1$$  作为 $$\mu$$  的一个估计。

   1. 它是无偏的，因为 $$\mathbb E[x_1]=\mu$$ ，所以不论观测到多少个数据点，该估计都是无偏的
   2. 但它不是一致的，因为他不满足 $$\text{plim}_{m\rightarrow \infty}\hat\mu_m=\mu$$ 

#### 方差

1. 估计量的方差记作 $$Var(\hat \theta)$$ ，标准差记作  $$SE(\hat\theta)$$ 。

   它们刻画的是：从潜在的数据分布中独立的获取样本集时，估计量的变化程度。

2. 例：一组服从均值为 $$\theta$$ 的伯努利分布的独立同分布样本 $$\{x_1,x_2,\cdots,x_m\}$$ 
   * $$\hat\theta_m=\frac 1m\sum_{i=1}^{m}x_i$$ 为 $$\theta$$ 的无偏估计。
   *  $$Var(\hat\theta_m)=\frac 1m \theta(1-\theta)$$ 。表明估计量的方差随 $$m$$ 增加而下降。
3. 估计量的方差随着样本数量的增加而下降，这是所有估计量的共性。
4. 例：均值估计 $$\hat\mu_m=\frac 1m\sum_{i=1}^{m}x_i$$ ，其标准差为： $$SE(\hat\mu_m)=\sqrt{ Var\left[\frac 1m\sum_{i=1}^{m}x_i\right]}=\frac{\sigma}{\sqrt{m}}$$ 

   其中 $$\sigma$$ 是样本 $$x_i$$  的真实标准差，但是这个量难以估计。实际上 $$\sqrt{\frac 1m\sum_{i=1}^{m}(x_i-\hat\mu_m)^{2}}$$ 和 $$\sqrt{\frac {1}{m-1}\sum_{i=1}^{m}(x_i-\hat\mu_m)^{2}}$$  都不是真实标准差  $$\sigma$$ 的无偏估计，这两种方法都倾向于低估真实的标准差。

   实际应用中， $$\sqrt{\frac {1}{m-1}\sum_{i=1}^{m}(x_i-\hat\mu_m)^{2}}$$ 是一种比较合理的近似估计，尤其是当$$m$$  较大的时候。

#### 偏差方差分解

1. 偏差和方差衡量的是估计量的两个不同误差来源：
   * 偏差衡量的是偏离真实值的误差的期望。
   * 方差衡量的是由于数据采样的随机性可能导致的估计值的波动。
2. 通常希望的是：
   * 估计量的偏差比较小，即：估计量的期望值接近真实值。
   * 估计量的方差比较小，即：估计量的波动比较小。
3. 假设：

   * 在训练集为 $$\mathbb D$$ 上学习到的模型为 $$f_\mathbb D(\mathbf{\vec x};\mathbb D)$$ 。

     > 不同的训练集训练得到不同的模型，因此模型与训练集 $$\mathbb D$$ 相关。

   * 样本 $$\mathbf{\vec x}$$ 的观测值为 $$\tilde y$$ ，其真实值为 $$y$$。其中 $$\tilde y=y+\epsilon$$ ，  $$\epsilon$$ 为观测误差。

     > 观测误差是由人工标注失误引起的。

   * 观察误差的期望为$$0$$： $$\mathbb E_{\mathbb D}(\epsilon)=0$$ 。
   * 观测误差 $$\epsilon$$ 与真实值 $$y$$ 是相互独立的。即有： $$\mathbb E_{\mathbb D}(y\epsilon) =\mathbb E_{\mathbb D}(y )  \times \mathbb E_{\mathbb D}(\epsilon) = 0 $$ 。
   * 样本 $$\mathbf{\vec x}$$ 的估计量为 $$\hat y_{\mathbb D}=f_\mathbb D(\mathbf{\vec x};\mathbb D)$$ 。

   定义：

   * 损失函数为平方损失函数： $$L(\tilde y,\hat y_{\mathbb D})=(\tilde y-\hat y_{\mathbb D})^2$$ 。
   * 对未知样本 $$\mathbf{\vec x}$$ ：
     * 预测偏差为： $$bias =(\mathbb E_{\mathbb D}(\hat y_{\mathbb D}) - y)^2$$ 。它刻画了期望输出与真实值之间的差别。
     * 预测方差为： $$var =Var(\hat y_{\mathbb D})=\mathbb E_\mathbb D\left[(\mathbb E(\hat y_{\mathbb D})-\hat y_{\mathbb D})^{2}\right]$$ 。它刻画了模型输出随着训练集  $$\mathbb D$$ 的不同从而导致的波动。
     * 噪声方差为： $$noise=Var(\epsilon)=\mathbb E_\mathbb D\left[(\tilde y-y)^{2}\right]$$ 。它刻画了不同训练集 $$\mathbb D$$ 中的噪音波动。

   则未知样本 $$\mathbf{\vec x}$$ 的泛化误差定义为损失函数的期望： $$Loss = \mathbb E_\mathbb D\left[(\hat y-\tilde y)^{2}\right]=  \mathbb E_\mathbb D\left[(f_\mathbb D(\mathbf{\vec x};\mathbb D)-\tilde y)^{2}\right]$$ 。其中使用观测值 $$\tilde y$$  而不是真实值 $$y$$ ，是因为观测值已知而真实值未知。

   则有： $$Loss = \mathbb E_\mathbb D\left[(\hat y_\mathbb D-\tilde y)^{2}\right] =\mathbb E_\mathbb D\left[(\hat y_\mathbb D-\mathbb E_\mathbb D(\hat y_\mathbb D))^{2}\right]+(\mathbb E_\mathbb D(\hat y_\mathbb D)-y)^{2}+\mathbb E_\mathbb D\left[(\tilde y-y)^{2}\right]\\ = var+bias+var$$ 

   于是**泛化误差可以分解为偏差、方差和噪声之和**：

   * 偏差  ：**度量了学习算法的期望预测与真实结果之间的偏离程度，刻画了学习算法本身的拟合能力。**
   * 方差 ：**度量了训练集的变动所导致的学习性能的变化，刻画了数据扰动造成的影响**。
   * 噪声  ：度量了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度。

   偏差-方差分解表明：泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度共同决定的。

4. 偏差-方差分解中，噪声也可以称作最优误差或者贝叶斯误差。如：在图像识别的问题中，人眼识别的错误率可以视作最优误差。

   在工程实际中，通常会考察`特征完全相同，但是标签不同` 的那些样本的数量。这种样本越多，则代表`必须犯的错误` 越大。因此实际应用中可以将这个比例作为贝叶斯误差。

5. 偏差、方差与模型容量有关。用`MSE`衡量泛化误差时，增加容量会增加方差、降低偏差。

   * 偏差降低，是因为随着容量的增大，模型的拟合能力越强：对给定的训练数据，它拟合的越准确。
   * 方差增加，是因为随着容量的增大，模型的随机性越强：对不同的训练集，它学得的模型可能差距较大。

6. 一般来说，偏差和方差是由冲突的，这称作偏差-方差窘境`bias-variance dilemma`。

   给定学习任务：

   * 在训练不足时模型的拟合能力不够强，训练数据的扰动不足以使模型产生显著变化，此时偏差主导了泛化误差。
   * 随着训练程度的加深模型的拟合能力逐渐增强，训练数据发生的扰动逐渐被模型学习到，方差逐渐主导了泛化误差。
   * 在训练充分后模型的拟合能力非常强，训练数据发生的轻微扰动都会导致模型发生显著变化。

     若训练数据自身的、非全局的特性被模型学到了，则将发生过拟合。

#### 误差诊断

1. 通常偏差方差反映了模型的过拟合与欠拟合。
   * **高偏差对应于模型的欠拟合**：模型过于简单，以至于未能很好的学习训练集，从而使得训练误差过高。

     此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。

   * **高方差对应于模型的过拟合**：模型过于复杂，以至于将训练集的细节都学到，将训练集的一些细节当做普遍的规律，从而使得测试集误差与训练集误差相距甚远。

     此时模型预测的偏差较小，表示预测较准确。但是模型预测的方差较大，表示预测较不稳定。
2. 误差诊断：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。

   * 如果训练误差较高：说明模型的方差较大，模型出现了欠拟合。
   * 如果训练误差较低，而测试误差较高：说明模型的偏差较大，出现了过拟合。
   * 如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。
   * 如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。

   上述分析的前提是：训练集、测试集的数据来自于同一个分布，且最优误差较小。否则讨论更复杂。

#### 误差缓解

1. 高方差和高偏差是两种不同的情况。如果算法存在高偏差的问题，则准备更多训练数据其实没什么卵用。

   所以首先要清楚：问题是高偏差还是高方差还是二者兼有。

2. 如果模型存在高偏差，则通过以下策略可以缓解：
   * 选择一个容量更大、更复杂的模型。
   * 使用更先进的最优化算法。该策略通常在神经网络中使用。
3. 如果模型存在高方差，则通过以下策略可以缓解：
   * 增加更多的训练数据。它通过更多的训练样本来对模型参数增加约束，会降低模型容量。

     如果有更多的训练数据，则一定会降低方差。

   * 使用正则化。它通过正则化项来对模型参数增加约束，也会降低模型容量。

     有时候更多的训练数据难以获取，只能使用正则化策略。
4. **通常优先解决高偏差的问题。这是最低标准，要反复尝试，直到训练误差降低到足够小。**

   **然后试图降低方差。**

   **总之就是不断重复尝试，直到找到一个低偏差、低方差的模型。**

### 参数估计准则

#### 最大似然估计

1. 假设数据集 $$\mathbf X=\{\mathbf{\vec x}_1,\mathbf{\vec x}_2,\cdots,\mathbf{\vec x}_m\}$$ 中的样本独立同分布地由 $$p_{data}(\mathbf{\vec x})$$ 产生，但是该分布是未知的。 $$p_{model}(\mathbf{\vec x};\theta)$$ 是一族由 $$\theta$$ 参数控制的概率分布函数族，希望通过 $$p_{model}(\mathbf{\vec x};\theta)$$ 来估计真实的概率分布函数 $$p_{data}(\mathbf{\vec x})$$ ，也就是要估计 $$\theta$$ 参数。
2. 最大似然估计最大化数据集 $$\mathbf X$$  出现的概率。即： $$\theta_{ML}=\arg\max_{\theta}p_{model}(\mathbf X;\theta) =\arg\max_\theta\prod_{i=1}^{m}p_{model}(\mathbf{\vec x}_i;\theta)$$ 
   * 由于概率的乘积会因为很多原因不便使用（如容易出现数值下溢出），因此转换为对数的形式： $$\theta_{ML}=\arg\max_\theta\sum_{i=1}^{m}\log p_{model}(\mathbf{\vec x}_i;\theta)$$ 。
   * 因为 $$m$$ 与 $$\theta$$ 无关，因此它也等价于： $$\theta_{ML}=\arg\max_\theta\sum_{i=1}^{m}\frac 1m \log p_{model}(\mathbf{\vec x}_i;\theta)$$  。
   * 由于数据集的经验分布为： $$\hat p_{data}(\mathbf{\vec x})=\frac 1m\sum_{i=1}^{m}\delta(\mathbf{\vec x}-\mathbf{\vec x}_i)$$ ，其中 $$\delta(\cdot)$$ 为狄拉克函数。因此： $$\theta_{ML}=\arg\max_\theta\mathbb E_{\mathbf{\vec x}\sim \hat p_{data}} \log p_{model}(\mathbf{\vec x};\theta)$$ 。
3. 考虑数据集的经验分布 $$\hat p_{data}$$ 和真实分布函数的估计量 $$p_{model}$$ 之间的差异，`KL`散度（ 在信息系统中称为**相对熵**）为： $$D|_{KL}(\hat p_{data} || p_{model};\theta) =\mathbb E_{\mathbf{\vec x}\sim \hat p_{data}}[\log \hat p_{data}(\mathbf{\vec x})-\log  p_{model}(\mathbf{\vec x;\theta})]$$ 

   由于 $$\log \hat p_{data}(\mathbf{\vec x})$$  与 $$\theta$$ 无关，因此要使得 $$D|_{KL}(\hat p_{data} || p_{model};\theta)$$ 最小，则只需要最小化 $$\mathbb E_{\mathbf{\vec x}\sim \hat p_{data}}[-\log  p_{model}(\mathbf{\vec x};\theta)]$$ 。也就是最大化 $$\mathbb E_{\mathbf{\vec x}\sim \hat p_{data}} \log p_{model}(\mathbf{\vec x};\theta)$$ 。

   因此：**最大似然估计就是最小化数据集的经验分布** $$\hat p_{data}$$  **和真实分布函数的估计量**  $$p_{model}$$ **之间的差异** 。

4. 最大似然估计可以扩展到估计条件概率。

   假设数据集 $$\mathbf X=\{\mathbf{\vec x}_1,\mathbf{\vec x}_2,\cdots,\mathbf{\vec x}_m\}$$ ，对应的观测值为 $$\mathbf Y=\{y_1,y_2,\cdots,y_m\}$$ 。则条件概率的最大似然估计为： $$\theta_{ML}=\arg\max_\theta p(\mathbf Y\mid \mathbf X;\theta)$$ 。

   如果样本是独立同分布的，则可以分解成： $$\theta_{ML}=\arg\max_\theta\sum_{i=1}^{m}\log p(y_i\mid \mathbf{\vec x}_i;\theta)$$ 。

5. 最大似然估计有两个很好的性质：
   * 在某些条件下，最大似然估计具有一致性。这意味着当训练样本数量趋向于无穷时，参数的最大似然估计依概率收敛到参数的真实值。

     这些条件为：

     * 真实分布 $$p_{data}$$ 必须位于分布函数族 $$p_{model}(\cdot;\theta)$$ 中；否则没有估计量可以表示 $$p_{data}$$ 。
     * 真实分布 $$p_{data}$$ 必须对应一个 $$\theta$$ 值；否则从最大似然估计恢复出真实分布 $$p_{data}$$ 之后，也不能解出参数 $$\theta$$ 。

   * 最大似然估计具有很好的统计效率`statistic efficiency`。即只需要较少的样本就能达到一个良好的泛化误差。
6. 最大似然估计通常是机器学习中的首选估计准则。
7. 当样本数量太少导致过拟合时，正则化技巧是最大似然的有偏估计版本。

#### 贝叶斯估计

**贝叶斯估计 vs 最大似然估计**

1. 在最大似然估计中，频率学派的观点是：真实参数  是未知的固定的值，而点估计  是随机变量。因为数据是随机生成的，所以数据集是随机的。

   在贝叶斯估计中，贝叶斯学派认为：数据集是能够直接观测到的，因此不是随机的。而真实参数  是未知的、不确定的，因此  是随机变量。

   * 对  的已知的知识表示成先验概率分布  ：表示在观测到任何数据之前，对于参数  的可能取值的一个分布。

     在机器学习中，一般会选取一个相当宽泛的（熵比较高）的先验分布，如均匀分布。

   * 假设观测到一组数据  ，根据贝叶斯法则，有：

2. 贝叶斯估计与最大似然估计有两个重要区别：
   * 贝叶斯估计预测下，一个样本的分布为：

     而最大似然估计预测下，一个样本的分布为： 

   * 贝叶斯估计会使得概率密度函数向着先验概率分布的区域偏移。
3. 当训练数据有限时，贝叶斯估计通常比最大似然估计泛化性能更好。

   当训练样本数量很大时，贝叶斯估计往往比最大似然估计计算代价较高。

**最大后验估计**

1. 有时候希望获取参数  的一个可能的值，而不仅仅是它的一个分布。此时可以通过最大后验估计`MAP` 选择后验概率最大的点：
2. 最大后验估计具有最大似然估计没有的优势：拥有先验知识带来的信息。该信息有助于减少估计量的方差，但是增加了偏差。
3. 一些正则化方法可以被解释为最大后验估计，正则化项就是对应于  。
   * 并非所有的正则化方法都对应为某个最大后验估计。

     如：有些正则化项依赖于数据，则显然不是一个先验概率分布
4. 最大后验估计估计`MAP` 提供了一个直观的方法去设计复杂的、可解释的正则化项。

   更复杂的正则化项可以通过先验分布为混合高斯分布得到（而不仅仅是一个单独的高斯分布）。

