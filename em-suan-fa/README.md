---
description: 'Expectation-Maximization algorithm, EM'
---

# EM算法

1. 如果概率模型的变量都是**观测变量**，则给定数据之后，可以直接用极大似然估计法或者贝叶斯估计法来估计模型参数。

   但是当模型含有隐变量时，就不能简单的使用这些估计方法。此时需要使用`EM` 算法。

   * `EM` 算法是一种迭代算法。
   * `EM` 算法专门**用于含有隐变量的概率模型参数的极大似然估计，或者极大后验概率估计。**

2. `EM`算法的每次迭代由两步组成：

   * `E`步求期望。
   * `M`步求极大。

   所以`EM`算法也称为期望极大算法。

## 一、示例

#### 1.1 身高抽样问题

1. 假设学校所有学生中，男生身高服从正态分布 $$\mathcal N(\mu_1,\sigma_1^2)$$ ， 女生身高服从正态分布  $$\mathcal N(\mu_2,\sigma_2^2)$$ 。

   现在随机抽取200名学生，得到这些学生的身高 $$\{x_1,x_2,\cdots,x_n\}$$ ，求参数 $$\{\mu_1,\sigma_1^2,\mu_2,\sigma_2^2\}$$ 的估计。

2. 定义隐变量为 $$z$$ ，其取值为 $$\{0,1\}$$ ，分别表示`男生、女生` 。

   * 如果隐变量是已知的，即已知每个学生是男生还是女生 $$\{z_1,z_2,\cdots,z_n\}$$ ，则问题很好解决：
     * 统计所有男生的身高的均值和方差，得到 $$\{\mu_1,\sigma_1^2\}$$ ： $$\mu_1 = \text{avg} \{x_i\mid z_i=0\}\quad \sigma_1^2 = \text{var} \{x_i\mid z_i=0\}$$ 

       其中 $$\{x_i\mid z_i=0\}$$ 表示满足 $$z_i=0$$  的 $$x_i$$ 构成的集合。 分别表示平均值和方差。

     * 统计所有女生的身高的均值和方差，得到 $$\{\mu_2,\sigma_2^2\}$$ ： $$\mu_2 = \text{avg} \{x_i\mid z_i=1\}\quad \sigma_2^2 = \text{var} \{x_i\mid z_i=1\}$$ 

       其中 $$\{x_i\mid z_i=1\}$$ 表示满足 $$z_i=1$$  的  $$x_i$$ 构成的集合。 $$\text{avg},\text{var}$$ 分别表示平均值和方差。
   * 如果已知参数 $$\{\mu_1,\sigma_1^2,\mu_2,\sigma_2^2\}$$ ，则任意给出一个学生的身高 $$x$$  ，可以知道该学生分别为男生/女生的概率。 $$p_1=\frac{1}{\sqrt{2\pi} \times \sigma_1}\exp\left(-\frac{(x-\mu_1)^2}{2\sigma^2_1}\right)\\ p_2=\frac{1}{\sqrt{2\pi} \times \sigma_2}\exp\left(-\frac{(x-\mu_2)^2}{2\sigma^2_2}\right)$$ 

     则有： $$p(z=0\mid x)=\frac{p_1}{p_1+p_2},p(z=1\mid x)=\frac{p_2}{p_1+p_2}$$ 。因此也就知道该学生更可能为男生，还是更可能为女生。

   因此：参数 $$\{\mu_1,\sigma_1^2,\mu_2,\sigma_2^2\} \Leftrightarrow$$ `学生是男生/女生`，这两个问题是相互依赖，相互纠缠的。

3. 为解决该问题，通常采取下面步骤：
   * 先假定参数的初始值： $$\{\mu_1^{<0>},\sigma_1^{2<0>},\mu_2^{<0>},\sigma_2^{2<0>}\}$$ 。
   * 迭代 ： $$i=0,1,\cdots$$ 
     * 根据 $$\{\mu_1^{<i>},\sigma_1^{2<i>},\mu_2^{<i>},\sigma_2^{2<i>}\}$$ 来计算每个学生更可能是属于男生，还是属于女生。

       这一步为`E` 步（`Expectation`），用于计算隐变量的后验分布  $$p(z\mid x)$$ 。

     * 根据上一步的划分，统计所有男生的身高的均值和方差，得到  $$\{\mu_1^{<i+1>},\sigma_1^{2<i+1>}\}$$ ；统计所有女生的身高的均值和方差，得到  $$\{\mu_2^{<i+1>},\sigma_2^{2<i+1>}\}$$ 。

       这一步为 `M` 步（`Maximization` ），用于通过最大似然函数求解正态分布的参数。

     * 当前后两次迭代的参数变化不大时，迭代终止。

#### 1.2 三硬币模型

1. 已知三枚硬币 `A`，`B`，`C` ，这些硬币正面出现的概率分别为 $$\pi,p,q$$ 。进行如下试验：  


   * 先投掷硬币 `A`，若是正面则选硬币 `B`；若是反面则选硬币 `C` 。
   * 然后投掷被选出来的硬币，投掷的结果如果是正面则记作 `1`；投掷的结果如果是反面则记作`0` 。
   * 独立重复地 $$N$$ 次试验，观测结果为： `1,1,0,1,0,...0,1` 。

   现在只能观测到投掷硬币的结果，无法观测投掷硬币的过程，求估计三硬币正面出现的概率。

2. 设：

   * 随机变量 $$Y$$ 是观测变量，表示一次试验观察到的结果，取值为 `1` 或者`0`
   * 随机变量 $$Z$$ 是隐变量，表示未观测到的投掷`A`硬币的结果，取值为 `1` 或者 `0`
   *  $$\theta=(\pi,p,q)$$ 是模型参数

   则： $$P(Y;\theta)=\sum_{Z}P(Y,Z;\theta)=\sum_{Z}P(Z;\theta)P(Y\mid Z;\theta)\\ =\pi p^{Y}(1-p)^{1-Y}+(1-\pi)q^{Y}(1-q)^{1-Y}$$ 

   注意：随机变量 $$Y$$ 的数据可以观测，随机变量 $$Z$$ 的数据不可观测

3. 将观测数据表示为 $$\mathbb Y=\{y_1,y_2,\cdots,y_N\}$$ ，未观测数据表示为 $$\mathbb Z=\{z_1,z_2,\cdots,z_N\}$$ 。

   由于每次试验之间都是独立的，则有： $$P(\mathbb Y;\theta)=\prod_{j=1}^{N}P(Y=y_i;\theta)=\prod_{j=1}^{N}[\pi p^{y_j}(1-p)^{1-y_j}+(1-\pi)q^{y_j}(1-q)^{1-y_j}]$$ 

4. 考虑求模型参数 $$\theta=(\pi,p,q)$$ 的极大似然估计，即： $$\hat \theta=\arg\max_{\theta}\log P(\mathbb Y;\theta)$$ 

   这个问题没有解析解，只有通过迭代的方法求解，`EM`算法就是可以用于求解该问题的一种迭代算法。

5. `EM`算法求解：

   首先选取参数的初值，记作 $$\theta^{<0>}=(\pi^{<0>},p^{<0>},q^{<0>})$$ ，然后通过下面的步骤迭代计算参数的估计值，直到收敛为止：

   设第 $$i$$ 次迭代参数的估计值为： $$\theta^{<i>}=(\pi^{<i>},p^{<i>},q^{<i>})$$ ， 则`EM`算法的第 $$i+1$$ 次迭代如下：

   * `E`步：计算模型在参数 $$\theta^{<i>}=(\pi^{<i>},p^{<i>},q^{<i>})$$ 下，观测数据 $$y_j$$ 来自于投掷硬币 `B` 的概率： $$\mu^{<i+1>}_j=\frac{\pi^{<i>}(p^{<i>})^{y_j}(1-p^{<i>})^{1-y_j}}{\pi^{<i>}(p^{<i>})^{y_j}(1-p^{<i>})^{1-y_j}+(1-\pi^{<i>})(q^{<i>})^{y_j}(1-q^{<i>})^{1-y_j}}$$ 

     它其实就是 $$P(Z=1\mid Y=y_j)$$ ，即：已知观测变量 $$Y=y_j$$ 的条件下，观测数据 $$y_i$$ 来自于投掷硬币 `B` 的概率。

   * `M` 步：计算模型参数的新估计值： $$\pi^{<i+1>}=\frac 1N\sum_{j=1}^{N}\mu_j^{<i+1>}\\ p^{<i+1>}=\frac{\sum_{j=1}^{N}\mu_j^{<i+1>}y_j}{\sum_{j=1}^{N}\mu_j^{<i+1>}}\\ q^{<i+1>}=\frac{\sum_{j=1}^{N}(1-\mu_j^{<i+1>})y_j}{\sum_{j=1}^{N}(1-\mu_j^{<i+1>})}$$ 
     * 第一个式子：通过后验概率 $$P(Z \mid Y)$$  估计值的均值作为先验概率 $$\pi$$ 的估计。
     * 第二个式子：通过条件概率 $$P(Y\mid Z=1)$$ 的估计来求解先验概率 $$p$$ 的估计。
     * 第三个式子：通过条件概率 $$P(Y\mid Z=0)$$ 的估计来求解先验概率 $$q$$ 的估计。

6. `EM` 算法的解释：
   * 初始化：随机选择三枚硬币 `A`，`B`，`C` 正面出现的概率 $$\pi,p,q$$ 的初始值 $$\pi^{<0>},p^{<0>},q^{<0>}$$  。
   * `E` 步：在已知概率 $$\pi,p,q$$ 的情况下，求出每个观测数据 $$y_i$$ 是来自于投掷硬币 `B` 的概率。即： 。

     于是对于 $$N$$  次实验，就知道哪些观测数据是由硬币 `B` 产生，哪些是由硬币 `C` 产生。

   * `M` 步：在已知哪些观测数据是由硬币 `B` 产生，哪些是由硬币 `C` 产生的情况下：
     *  $$\pi$$ 就等于硬币 `B` 产生的次数的频率。
     *  $$p$$ 就等于硬币`B` 产生的数据中，正面向上的频率。
     *  $$q$$ 就等于硬币 `C` 产生的数据中，正面向上的频率。

