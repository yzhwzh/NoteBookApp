---
description: Distribution
---

# 1. 重要分布

### **基本概念**

1. 样本与总体同分布，且相互独立；
2. 样品$$X_i$$的分布函数为$$F(X_i)$$，则其简单随机样本的联合分布函数为$$F(X_1)F(X_2)...F(X_n) = \prod_{i=1}^nF(X_i)$$
3. 设总体$$X$$的分布函数为$$F(x)$$,从该总体中取样本观测值为$$x_1,x_2,...,x_n$$,将其样本值由小到大排列成 $$x_1^* <= x_2^* <=...<=x_n^*$$ ,令 $$F^*(x)=\left\{\begin{aligned}0, && x\lt x_1^* \\\frac{k}{n}, && x_k^* \le x \lt x_{k+1}^* \\1 && x \ge x_n^*\end{aligned}\right.$$ 称 $$F_n^*(x)$$ 为总体$$X$$的**经验分布函数**
4. 格里汶科定理：设$$X$$的总体分布函数为$$F(x)$$，经验分布函数为 $$F_n^*(x)$$ ,则有： $$P\{lim_{n\rightarrow \infty}sup_{-\infty < x < +\infty}|F^*_n(x)-F(x)|=0\}=1$$ 即当$$n\rightarrow \infty$$时， $$F_n^*(x)$$ 以概率为$$1$$均匀趋于$$F(x)$$,所以可以用经验分布函数去估计总体分布函数
5. **在随机事件的大量重复出现中，往往呈现几乎必然的规律，这个规律就是大数定律**。通俗地说，这个定理就是，在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。偶然中包含着某种必然。\(契比雪夫，随着样本容量$$n$$的增加，样本平均数将接近于总体平均数；伯努利，当$$n$$足够大时，事件$$A$$出现的频率将几乎接近于其发生的概率；辛钦大数定理，用算术平均值来近似实际真值是合理\)
6. 中心极限定理，是指概率论中讨论随机变量序列部分和分布渐近于正态分布的一类定理。这组定理是数理统计学和误差分析的理论基础，指出了大量随机变量近似服从正态分布的条件。它是概率论中最重要的一类定理，有广泛的实际应用背景。

   \*\*\*\*

#### **统计量**

1. 统计量：为总体的样本，能实际取值，**且不含有未知参数**,（总体一般是未知的，例如总体均值和方差$$(\mu,\sigma^2)$$，只能通过样本去估计）
2. 常用统计量：

样本均值：

$$
\overline{X} = \frac{1}{n}\sum_{i=1}^nX_i
$$

$$
E(\overline{X}) = \mu
$$

$$
D(\overline{X}) = D(\frac{1}{n}\sum_{i=1}^nX_i) = \frac{1}{n^2}\sum_{i=1}^nD(X_i) = \frac{1}{n^2}*n*\sigma^2 = \frac{\sigma^2}{n}
$$

样本方差：

$$
S^2 = \frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2 = \frac{1}{n-1}(\sum_1^nX_i^2-n\overline{X}^2)
$$

$$
E(S^2) = \frac{1}{n-1}(\sum_1^nE(X_i^2)-nE(\overline{X}^2)) = \frac{1}{n-1} \{\sum_1^n(D(X)+E^2(X))-n(D(\overline{X})+E^2(\overline{X}))\} = \frac{1}{n-1}(\sum_1^n(\sigma^2+\mu^2)-n(\frac{\sigma^2}{n}+\mu^2)) = \sigma^2
$$

样本$$k$$阶原点矩：

$$
A_k = \frac{1}{n}\sum_{i=1}^n X_i^k
$$

样本k阶中心矩：

$$
B_k = \frac{1}{n}\sum_{i=1}^n (X_i-\overline{X})^k
$$

### **重要分布：**

#### **1.** $$\chi^2$$**分布：**

设$$X_1,X_2,...,X_n$$相互独立，都服从标准正态分布$$N(0,1)$$,则称随机变量：

$$
\chi^2=\sum_{i=1}^nX_i^2
$$

所服从的分布为自由度为$$n$$的$$\chi^2$$分布，记为$$\chi^2 \sim \chi^2(n)$$。

$$\chi^2$$分布的密度函数为 \(自由度越大，最大值越小\)

$$
f(x;n)=\left\{
\begin{aligned}
\frac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}, && x\ge 0 \\
0, && x \lt 0 
\end{aligned}
\right.
$$

$$
\Gamma(x) = \int_0^{\infty}e^{-t}t^{x-1}dt,x\gt0
$$

$$\chi^2$$ 分布的性质：

a. 设$$X_1,X_2,...,X_n$$相互独立，都服从正态分布$$N(\mu,\sigma^2)$$则

$$
\sum_{i=1}^n(\frac{X_i-\mu}{\sigma})^2 = \frac{1}{\sigma^2}\sum_{i=1}^n(X_i-\mu)^2 \sim \chi^2(n)
$$

b. $$\chi^2$$分布的可加性，$$X_1\sim\chi^2(n_1),X_2\sim\chi^2(n_2)$$则$$X_1+X_2\sim\chi^2(n_1+n_2)$$

c. 若$$X \sim \chi^2(n)$$，则可以求得 $$E(X) = n; D(x) = 2n$$

#### **2. T分布**

设$$X\sim N(0,1),Y \sim \chi^2(n)$$,且$$X$$与$$Y$$相互独立，则称随机变量

$$
T=\frac{X}{\sqrt{Y/n}}
$$

所服从的分布为自由度为$$n$$的$$t$$分布，记为$$T \sim t(n)$$。

$$T$$分布的密度函数：

$$
f(t;n) = \frac{\Gamma[(n+1)/2]}{\Gamma(n/2)\sqrt{n\pi}}(1+\frac{t^2}{n})^{-\frac{n+1}{2}}, -\infty < t < +\infty
$$

**其为偶函数，**$$n$$**越大，峰度越高，越接近正态分布，**$$n>45$$**时，**$$t$$**分布近似**$$N(0,1)$$**分布.**

$$E(T) = 0, D(T) = n/(n-2), n>2$$

#### **3. F分布**

设$$X \sim \chi^2(n_1),Y \sim \chi^2(n_2)$$，且$$X$$与$$Y$$相互独立，则称统计量

$$
F=\frac{X/n_1}{Y/n_2}
$$

服从自由度为$$n_1$$及$$n_2$$的$$F$$分布，$$n_1$$为第一自由度，$$n_2$$为第二自由度，记作$$F \sim F(n_1,n_2)$$.

由定义可知

$$
\frac{1}{F} = \frac{Y/n_2}{X/n_1} \sim F(n_2,n_1)
$$

$$F$$分布的概率密度函数：

$$
f(x;n_1;n_2) = \left\{
\begin{aligned}
\frac{\Gamma(\frac{n_1+n_2}{2})}{\Gamma(\frac{n_1}{2})\Gamma(\frac{n_2}{2})}(\frac{n_1}{n_2})(\frac{n_1}{n_2}x)^{\frac{n_1}{2}-1}(1+\frac{n_1}{n_2}x)^{-\frac{n_1+n_2}{2}}, && x\ge 0 \\
0, && x \lt 0 
\end{aligned}
\right.
$$

#### 4.二项分布

 是$$n$$个独立的是/非试验中成功的次数的离散概率分布，其中每次试验的成功概率为$$p$$。这样的单次成功/失败试验又称为伯努利试验。实际上，当$$n = 1$$时，二项分布就是伯努利分布。二项分布是显著性差异的二项试验的基础。

#### 概率质量函数

$$
{\displaystyle f(k,n,p)=P(X=k)={n \choose k}p^{k}(1-p)^{n-k}}
$$

累积分布函数可以表示为

$$
{\displaystyle F(k,n,p)=P(X\le k)=\sum_{i=0}^{|x|}{n \choose k}p^{k}(1-p)^{n-k}}
$$

#### $$E(x) = np$$ ; $$D(x) = np(1-p)$$ 

> 如果$$n$$足够大，那么分布的偏度就比较小。在这种情况下，如果使用适当的连续性校正，那么$$B(n, p)$$的一个很好的近似是正态分布$$N(np,np(1-p))$$，$$n$$越大（至少20），近似越好，当$$p$$不接近0或1时更好。不同的经验法则可以用来决定$$n$$是否足够大，以及$$p$$是否距离0或1足够远：**一个规则是x=np和n\(1 − p\)都必须大于 5**。

> 当试验的次数趋于无穷大，而乘积$$np$$固定时，二项分布收敛于泊松分布。因此参数为$$\lambda= np$$的泊松分布可以作为二项分布$$B(n, p)$$的近似，如果$$n$$足够大，而$$p$$足够小

#### 5. 泊松分布  

泊松分布的概率函数为：

$$
P(X=k) = \frac{\lambda^k}{k!}e^{-\lambda},k=0,1,...
$$

泊松分布的参数$$\lambda$$是单位时间\(或单位面积\)内随机事件的平均发生次数。 泊松分布适合于描述单位时间内随机事件发生的次数。

泊松分布的期望和方差均为$$\lambda$$。

> **当二项分布的**$$n$$**很大而**$$p$$**很小时，泊松分布可作为二项分布的近似，其中**$$\lambda$$**为**$$np$$**。通常当**$$n \ge 20,p \le 0.05$$**时，就可以用泊松公式近似得计算。 事实上，泊松分布正是由二项分布推导而来的**

**6. 负二项分布**

负二项分布是统计学上一种描述在一系列独立同分布的伯努利试验中，失败次数到达指定次数（记为r）时成功次数的离散概率分布。比如，如果我们定义掷骰子随机变量x值为x=1时为失败，所有x≠1为成功，这时我们反复掷骰子直到1出现3次（失败次数r=3），此时非1数字出现次数的概率分布即为负二项分布。

 **若随机变量**$$X$$**服从参数为**$$p$$**的负二项分布，则记为**$$X\sim NB(r,p)$$\*\*\*\*

帕斯卡分布（**Pascal distribution，**来自Blaise Pascal）和波利亚分布（**Polya distribution**，又称罐子模型，来自George Pólya）均是负二项分布的特例。在工程，气候等领域中经常用“负二项分布”或“帕斯卡分布”来描述变量$$r$$为整数的情况，而使用“波利亚分布”来描述$$r$$取到实数值$$R$$的情况。

对于“传染性的”（"contagious"）的离散事件，**例如龙卷风爆发，相比泊松分布，波利亚分布由于允许其平均值和方差不同，而能够给出更精确的模型**。“传染性”的事件中，如果事件发生率相互独立，其发生率间的正相关性（即发生率间存在正协方差项）会导致变量分布有更大的方差。

**“负二项分布”与“二项分布”的区别在于：“二项分布”是固定试验总次数**$$N$$**的独立试验中，成功次数**$$k$$**的分布；而“负二项分布”是所有到失败**$$r$$**次时即终止的独立试验中，成功次数**$$k$$**的分布**。

#### 概率质量函数

 当$$r$$是整数时的负二项分布又称**帕斯卡分布**

$$
{\displaystyle f(k,r,p)=P(X=k)={k+r-1 \choose k}p^{k}(1-p)^{n-k}}
$$

其中$$k$$是成功的次数，$$r$$是失败的次数，$$p$$是事件成功的概率。在负二项分布的概率质量函数中，由于$$k+r$$次伯努利试验为独立同分布，每个失败$$r$$次、成功$$k$$次的事件的概率为$$(1 − p)^rp^k$$。**由于第**$$r$$**次失败一定是最后一次试验，所以应该在**$$k+r-1$$**次试验中选择**$$k$$**次成功，使用排列组合二项系数获取所有可能的选择数**。

### **概率分布的上侧分位数**

设$$X$$的概率密度函数为$$f(x),$$对于给定的正数，若存在一实数$$A_\alpha$$，使的

$$
P\{X>A_\alpha\} =  \int_{A_\alpha}^{\infty}f(x)dx = \alpha
$$

则称$$A_\alpha$$为$$X$$的上侧$$\alpha$$分位数。（$$\alpha$$是概率，$$A_\alpha$$是数值）

* 标准正态分布的上$$\alpha$$分位数

$$
P(X\le Z_{\alpha}) = \Phi(Z_{\alpha}) = 1-\alpha
$$

例如：

$$
\Phi(Z_{0.05}) = \Phi(1.645) =  1-0.05 = 0.95
$$

即1.645 为 标准正态分布的上0.05 \(5%\) 分位数; $$Z_{\alpha/2}$$**也称为双侧**$$\alpha$$**分位数**

* $$t$$分布的上$$\alpha$$分位数 若$$t \sim t(n)$$,称满足$$P\{t>t_\alpha(n)\} = \alpha$$的数$$t_\alpha(n)$$为$$t(n)$$上的$$\alpha$$分位数，易知$$t_{1-\alpha}(n) = - t_\alpha(n)$$;

当$$n\le45$$时直接查表；当$$n\gt45$$时, $$T \sim N(0,1)$$\(近似\)；故$$t_{\alpha}(n) \approx z_{\alpha}$$

* $$\chi^2$$分布的上$$\alpha$$分位数，设$$\chi^2 \sim \chi^2(n)$$,称满足$$P\{\chi^2 > \chi^2_{\alpha}(n)\} = \alpha$$的$$\chi^2_{\alpha}(n)$$为自由度为$$n$$的$$\chi^2$$分布的上$$\alpha$$分位数。

当$$n\le45$$时直接查表；当$$n\gt45$$时,$$\chi^2_{\alpha}(n) = \frac{1}{2}(Z_{\alpha}+\sqrt{2n-1})^2$$; 因为当$$n\gt45$$时，费歇证明了$$\sqrt{2\chi^2} \sim N(\sqrt{2n-1},1)$$，（n很大时，近似）；即$$\sqrt{2\chi^2} -\sqrt{2n-1}\sim N(0,1)$$故$$P\{\sqrt{2\chi^2} -\sqrt{2n-1} > Z_{\alpha}\} = \alpha \Rightarrow P\{\chi^2 > \frac{1}{2}(Z_{\alpha}+\sqrt{2n-1})^2\} = \alpha$$

* $$F$$分布的上$$\alpha$$分位数，若$$F \sim F(m,n)$$,称满足$$P\{F>F_{\alpha}(m,n)\} = \alpha$$的数$$F_{\alpha}(m,n)$$ 为$$F$$分布的上$$\alpha$$分位数。  

查表，可适当变形，$$F_{\alpha}(m,n) = \frac{1}{F_{1-\alpha}(n,m)}$$

### **重要推论**

设$$X_1,X_2,...,X_n$$是取自正态总体$$N(\mu,\sigma^2)$$的样本，$$\overline{X},S^2$$分别为样本均值和样本方差，则有： 

1. $$\overline{X} \sim N(\mu,\frac{\sigma^2}{n}) \Rightarrow \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)$$ 
2. （[证明](https://wenku.baidu.com/view/bb9093026d85ec3a87c24028915f804d2b1687e0.html?rec_flag=default&sxts=1567438644961)） $$\frac{(n-1)S^2}{\sigma^2} = \frac{\sum_{i=1}^n(X_i-\overline{X})^2}{\sigma^2} \sim \chi^2(n-1)$$ 
3. $$\overline{X},S^2$$相互独立
4. $$\frac{\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S^2}{\sigma^2(n-1)}}}  = \frac{\overline{X}-\mu}{S/\sqrt{n}} \sim t(n-1)$$ 



**两个样本相互独立** $$X\sim N(\mu_1,\sigma_1^2),Y\sim N(\mu_2,\sigma_2^2)$$;则$$\overline{X} \sim N(\mu_1,\frac{\sigma_1^2}{n_1});\overline{Y} \sim N(\mu_2,\frac{\sigma_2^2}{n_2}) \Rightarrow \overline{X}-\overline{Y} \sim N(\mu_1-\mu_2,\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2})$$

标准化后得到：

$$
\frac{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}} \sim N(0,1)
$$

同时：

$$
\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2} \sim F(n_1-1,n_2-1)
$$

若方差齐性$$\sigma_1^2=\sigma_2^2=\sigma^2$$, 则有：

$$
\frac{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}{S_W\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t(n_1+n_2-2)
$$

$$
S_W = \sqrt{\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}}
$$

因为

$$
V = \frac{(n_1-1)S_1^2}{\sigma^2} + \frac{(n_2-1)S_2^2}{\sigma^2} \sim \chi^2(n_1+n_2-2)
$$

$$
U = \frac{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}{\sigma\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim N(0,1)
$$

故

$$
\frac{U}{\sqrt{V/(n_1+n_2-2)}} \sim t(n_1+n_2-2)
$$

同时：

$$
\frac{S_1^2}{S_2^2} \sim F(n_1-1,n_2-1)
$$



