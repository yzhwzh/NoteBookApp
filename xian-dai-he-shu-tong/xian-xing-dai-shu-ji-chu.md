---
description: Linear Algebra
---

# 线性代数基础

**相关名词：**

1. 标量 scalar : 一个单独的数, 自然数、整数、实数
2. 向量 vector: 有序列的一列数，**一般指纵向量，向量默认都是指列向量** 
3. 矩阵 matrix: 二维数组
4. 张量 tensor: 超过二维的数组
5. 单位矩阵: 所有沿主对角线的元素都是1，而所有其他位置的元素都是0
6. 逆矩阵: 矩阵A的逆矩阵记作 $$A^{-1}$$ ，满足如下条件: $$A^{-1}*A = A*A^{-1} = I_n$$    矩阵可逆当且仅当它是满秩矩阵 （行秩是A的线性无关的横行的极大数目），即 $$|A|\neq0$$ ，若等于0，为奇异矩阵

   > 在线性代数范围内,可逆矩阵是方阵.之后有左逆矩阵,右逆矩阵,广义逆矩阵不一定是方阵。

7. 单位向量是具有单位范数的向量 $$||x||_2=1$$ 
8. 如果 $$x^T*y=0$$ ,那么向量$$x$$和$$y$$互相正交，若范数为都为1，称之为标准正交
9. 正交矩阵是指行向量和列向量分别_**标准正交**_的方阵；即A的各行是单位向量且两两正交，A的各列是单位向量且两两正交； $$A^T*A=I;A^T=A^{-1}$$ 
10. 长度为零的向量是零向量，也即模等于零的向量，记作0；零向量的方向是无法确定的。但我们规定：零向量的方向与任一向量平行，与任意向量共线，与任意向量垂直。
11. 设在矩阵$$A$$中有一个不等于0的$$r$$阶子式$$D$$，且所有$$r+1$$阶子式全等于0，那么$$D$$称为矩阵A的最高阶非零子式，数$$r$$称为矩阵A的秩。（子式为行列式） 
12. [幂等矩阵](https://baike.baidu.com/item/%E5%B9%82%E7%AD%89%E7%9F%A9%E9%98%B5/3002494)，若$$A$$为方阵，且$$A^2=A$$，则$$A$$称为幂等矩阵。
    1. 幂等矩阵的特征值只可能是0，1；
    2. 幂等矩阵可对角化；
    3. 幂等矩阵的迹等于幂等矩阵的秩，即$$tr(A)=rank(A)$$；
    4. 可逆的幂等矩阵为$$E$$；
    5. 方阵零矩阵和单位矩阵都是幂等矩阵；
    6. 幂等矩阵$$A$$满足：$$A(E-A)=(E-A)A=0$$；
    7. 幂等矩阵$$A$$：$$Ax=x$$的充要条件是$$x \in R(A)$$；

**克拉默法则,增广矩阵和逆矩阵求解线性方程组（A可逆的情况下）**

如果线性方程组的系数矩阵A的行列式不等于0，那么方程组有唯一解， $$x_1=\frac{|A_1|}{|A|}...x_n=\frac{|A_n|}{|A|}$$ ,其中 $$|A_j|$$ 是把系数矩阵$$A$$中的第$$j$$列的元素用方程组右端的常数项代替后的得到的$$n$$阶矩阵

求解线性方程组$$Ax=b$$\($$A$$为可逆矩阵\)时把增广矩阵$$(A,b)$$化为行最简形矩阵，其最后一列就是解向量 _用的是初等行变换，因为每一列都是与未知数对应的，不能进行列变换_，

$$AX=B\Rightarrow X=A^{-1}B$$，$$A$$可逆  
首非0元1，所在列的其他元均为0，即为行最简形

\*\*\*\*$$n$$**元线性方程组** $$Ax=b$$

1. 无解的充分必要条件是$$R(A)<R(A,b)$$;
2. 有唯一解的充要条件是$$R(A) = R(A,b) = n$$;
3. 有无限多解的充分必要条件是$$R(A) = R(A,b) < n$$;
4. n元其次线性方程组$$Ax=0$$ 有非0解的充要条件是$$R(A)<n$$;
5. 矩阵方程$$AX=B$$有解的充要条件 $$R(A) = R(A,B)$$

**范数**

衡量一个向量的大小，形式上$$L^p$$范数定义如下:$$||x||_p=(\sum_i|x_i|^p)^{\frac{1}{p}}$$;范数是将向量映射到非负值的函数，直观上来说，向量$$x$$的范数衡量从原点到点$$x$$的距离，进而范数是满足下列性质的任意函数： 1. $$f(x) = 0\Rightarrow x=0$$; 2. $$f(x+y)<=f(x)+f(y)$$; 3. $$\forall\alpha \in R, f(\alpha x) = |\alpha|f(x)$$;

> 1. 当p=2时,$$L^2$$范数被称为欧几里得范数，经常简化表示为$$||x||$$，略去小标2，但在应用中平方$$L^2$$范数应用更为广泛 ; 可以简单的通过点积进行计算  
> 2. 平方$$L^2$$范数在数学和计算上比$$L^2$$范数更为方便，例如求导，开根号求导更为复杂；但在很多情况下平方$$L^2$$范数也可能不受欢迎，因为他在原点附近增长缓慢，在某些机器学习应用中，区分恰好是0的元素和非0但值很小的元素很重要，在这些情况下，会使用$$L^1$$范数，即$$|||x||_1 = \sum_i|x_i|$$  
> 3. 另外一个经常出现的范数是$$L^\infty$$, 即$$||x||_\infty=max_{i}|x_i|$$  ，表示向量中具有最大幅值元素的绝对值

**Frobenius 范数**

衡量矩阵的大小$$||A||_F = \sqrt [2]{\sum_{i,j}A_{i,j}^2}$$; 另外向量的点积可以用范数来表示 $$x^T*y=||x||_2*||y||_2*\cos\theta$$ 可由余弦公式进行推导： $$c^2=a^2+b^2-2ab *cos\theta$$ 

**相关乘法**

1. 元素对应乘积 or Hadamard 乘积$$A \bigodot B$$ 每个对应位置上的元素相乘
2. 点积 $$A*B$$ 

**相关定义**

1. 对于$$ n$$ 维行（列）向量$$\alpha_1,\alpha_2,\alpha_3,...\alpha_n$$如果存在一组数,$$\lambda_1,\lambda_2,\lambda_3,...\lambda_m$$使得 $$\beta=\lambda_1*\alpha_1+\lambda_2*\alpha_2+\lambda_3*\alpha_3...+\lambda_n*\alpha_n$$ 则称向量$$\beta$$是向量组的一个线性组合，即可由向量组进行线性表示
2. 任一 $$n$$ 维向量都是单位向量的组的线性组合
3. 已知$$ n $$维行（列）向量组$$\alpha_1,\alpha_2,\alpha_3,...\alpha_n$$,如果存在不全为零的一组数$$\lambda_1,\lambda_2,\lambda_3,...\lambda_m$$使得 $$\lambda_1*\alpha_1+\lambda_2*\alpha_2+\lambda_3*\alpha_3...+\lambda_n*\alpha_n=0$$ 则称向量组线性相关，否则线性无关。向量组的相关性等价于这个齐次方程组有否非零解。
4. **运算**$$+$$**称为加法运算，为数乘运算，统称为线性运算，衍射而来线性空间**

**特征值与特征向量**

设$$A$$为$$n$$阶矩阵，若存在常数$$\lambda$$及$$n$$维非零向量$$x$$，使得$$Ax=\lambda x$$，则称$$\lambda$$是矩阵$$A$$的特征值，$$x$$是$$A$$属于特征值$$\lambda$$的特征向量

特征方程$$|A-\lambda E|$$,其个数为方程的次数，因此$$n$$阶矩阵$$A$$在复数范围内有$$n$$个特征值

设n阶矩阵$$A=(a_{ij})$$的特征值为$$\lambda_1,\lambda_2,...,\lambda_n$$则 1. $$\lambda_1+\lambda_2+...+\lambda_n=a_{11}+a_{22}+...+a_{nn}$$; 2. $$\lambda_1\lambda_2...\lambda_n=|A|$$; 故$$A$$是可逆矩阵的充要条件是他的$$n$$个特征值全不为0

> 因为如果$$v$$是$$A$$的特征向量，那么任何缩放后的向量$$sv,s\in R,s\neq0$$ 也是$$A$$的特征向量，此外$$sv$$与$$v$$有相同的特征值，故一般只考虑单位特征向量

**相似矩阵**

设$$A，B$$都是$$n$$阶矩阵，若有可逆矩阵$$P$$，使得$$P^{-1}AP=B$$,则称$$B$$是$$A$$的相似矩阵

相似矩阵的特征值和特征多项式相同

若n阶矩阵A与对角矩阵$$\Lambda=\begin{bmatrix}{\lambda_1}&{0}&{\cdots}&{0}\\{0}&{\lambda2}&{\cdots}&{0}\\{\vdots}&{\vdots}&{\ddots}&{\vdots}\\{0}&{0}&{\cdots}&{\lambda_n}\end{bmatrix}$$相似，则$$\lambda_1,\lambda_2,...,\lambda_n$$即是$$A$$的$$n$$个特征值

$$n$$阶矩阵$$A$$与对角阵相似的充要条件是$$A$$有$$n$$个线性无关的特征向量，因而$$n$$个特征值互不相等是对角阵相似的充分条件，**注：特征值中有重根，特征向量的几何重数也有可能等于代数重数，即n阶矩阵，特征值中有重根，但仍有可能找出n个线性无关的特征向量，如实对称阵一定可对角化，故一定有n个线性无关的特征向量**。

**方阵对角化**

令$$M$$为 $$n*n$$ 矩阵，其特征值为$$\lambda_1,\lambda_2,\lambda_3,...\lambda_n$$，特征向量为$$V_1,V_2,V_3...V_n$$，形成线性无关集合，以每个特征向量为列构成矩阵$$A$$，如下所示:$$A=[V_1\ V_2\ V_3\ ...\ V_n]$$。该矩阵$$A$$可以将$$M$$对角化，即$$A^{-1}MA=\begin{bmatrix}{\lambda_1}&{0}&{\cdots}&{0}\\{0}&{\lambda2}&{\cdots}&{0}\\{\vdots}&{\vdots}&{\ddots}&{\vdots}\\{0}&{0}&{\cdots}&{\lambda_n}\end{bmatrix}$$  
反之，如果存在可逆矩阵$$A$$，使得$$A^{-1}MA$$为对角阵，_则矩阵_$$A$$_的列等于矩阵_$$M$$_的特征向量，对角阵的主对角元素为矩阵_$$M$$_的特征值_。

证明：首先计算矩阵乘积$$MA$$。由于矩阵$$A$$的第$$j$$列对应特征向量$$V_j$$，则$$MA$$的第$$j$$列等于$$MV_j$$。由于$$V_j$$为特征向量，则$$MV_j=\lambda_jV_j$$ ，矩阵乘积$$MA$$可写为$$MA=[\lambda_1V_1\ \lambda_2V_2\ ...\ \lambda_nV_n]=A\Lambda$$ 进一步$$A^{-1}MA=A^{-1}A\Lambda=\Lambda$$

**进而方阵**$$M$$**的特征分解可以记作**$$M=A\Lambda A^{-1}$$\*\*\*\*

**奇异值分解（singular value decomposition 即SVD）**

奇异矩阵是线性代数的概念，就是该矩阵的秩不是满秩。首先，看这个矩阵是不是方阵（即行数和列数相等的矩阵。若行数和列数不相等，那就谈不上奇异矩阵和非奇异矩阵）

奇异值分解则是特征分解在任意矩阵上的推广

假设A是一个$$m×n$$阶矩阵，其中的元素全部属于域$$K$$，也就是实数域或复数域。如此则存在一个分解使得$$A=UDV^T$$,$$ U$$是$$m * m$$的矩阵，$$D$$是$$m*n$$的矩阵，$$V$$是一个$$n*n$$的矩阵；$$U$$和$$V$$都定义为**正交矩阵**，矩阵$$D$$定义为对角方阵，$$U$$的列向量为左奇异向量，$$V$$为右奇异向量

**向量正交性**

若$$n$$维向量$$a_1,a_2,...,a_r$$是一组两两正交的非零向量，则$$a_1,a_2,...,a_r$$线性无关。

标准正交化（施密特正交化）

$$b_1 = a_1$$  
$$b_2 = a_2-\frac{[b_1,a_2]}{[b_1,b_1]}b_1$$  
$$...$$  
$$b_r = a_r-\frac{[b_1,a_r]}{[b_1,b_1]}b_1-\frac{[b_2,a_r]}{[b_2,b_2]}b_2-...-\frac{[b_{r-1},a_r]}{[b_{r-1},b_{r-1}]}b_{r-1}$$

然后把他们单位化，即取$$e_r=\frac{1}{||b_r||}b_r$$

如果$$n$$阶矩阵$$A$$满足$$A^TA=E$$,那么称$$A$$为正交\(矩\)阵

**对称矩阵**

1. 对称矩阵的特征值为实数
2. 设$$\lambda_1,\lambda_2$$是对称矩阵$$A$$的两个特征值，$$p_1,p_2$$是对应的特征向量，若$$\lambda_1 \neq \lambda_2$$,则$$p_1$$与$$p_2$$正交
3. 设$$A$$为$$n$$阶对称矩阵，则必有正交矩阵$$P$$,使$$P^{-1}AP=P^{T}AP=\Lambda$$

