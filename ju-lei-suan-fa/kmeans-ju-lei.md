# K-means 聚类

## **K-means**

1. 给定样本集 $$\mathbb D=\{\mathbf{\vec x}_1,\mathbf{\vec x}_2,\cdots,\mathbf{\vec x}_N\}$$ ， 假设一个划分为 $$\mathcal C=\{\mathbb C_1,\mathbb C_2,\cdots,\mathbb C_K\}$$ 。

   定义该划分的平方误差为： $$err=\sum_{k=1}^{K}\sum_{\mathbf{\vec x}_i \in \mathbb C_k}||\mathbf{\vec x}_i-\vec \mu_k||_2^{2}$$ 

   其中 $$\vec \mu_k=\frac {1}{|\mathbb C_k|}\sum_{\mathbf{\vec x}_i \in \mathbb C_k}\mathbf{\vec x}_i$$  是簇  $$\mathbb C_k$$ 的均值向量。

   *  $$err$$ 刻画了簇类样本围绕簇均值向量的紧密程度，其值越小，则簇内样本相似度越高。
   * `k-means` 算法的优化目标为：最小化  。即 $$\min_{\mathcal C} \sum_{k=1}^{K}\sum_{\mathbf{\vec x}_i \in C_k}||\mathbf{\vec x}_i-\vec \mu_k||_2^{2}$$ ： 。

2. `k-means` 的优化目标需要考察 $$\mathbb D$$ 的所有可能的划分，这是一个`NP`难的问题。实际上`k-means` 采用贪心策略，通过迭代优化来近似求解。
   * 首先假设一组均值向量。
   * 然后根据假设的均值向量给出了  的一个划分。
   * 再根据这个划分来计算真实的均值向量：
     * 如果真实的均值向量等于假设的均值向量，则说明假设正确。根据假设均值向量给出的  的一个划分确实是原问题的解。
     * 如果真实的均值向量不等于假设的均值向量，则可以将真实的均值向量作为新的假设均值向量，继续迭代求解。
3. 这里的一个关键就是：给定一组假设的均值向量，如何计算出  的一个簇划分？

   `k`均值算法的策略是：样本离哪个簇的均值向量最近，则该样本就划归到那个簇。

4. `k-means` 算法：
   * 输入：
     * 样本集 。
     * 聚类簇数 。
   * 输出：簇划分 。
   * 算法步骤：
     * 从  中随机选择  个样本作为初始均值向量  。
     * 重复迭代直到算法收敛，迭代过程：
       * 初始化阶段：取 
       * 划分阶段：令  ：
         * 计算  的簇标记： 。

           即：将  离哪个簇的均值向量最近，则该样本就标记为那个簇。

         * 然后将样本  划入相应的簇： 。
       * 重计算阶段：计算  ： 。
       * 终止条件判断：
         * 如果对所有的 ，都有 ，则算法收敛，终止迭代。
         * 否则重赋值  。
5. `k-means` 优点：
   * 计算复杂度低，为  ，其中  为迭代次数。

     通常  和  要远远小于 ，此时复杂度相当于 。

   * 思想简单，容易实现。
6. `k-means` 缺点：
   * 需要首先确定聚类的数量  。
   * 分类结果严重依赖于分类中心的初始化。

     通常进行多次`k-means`，然后选择最优的那次作为最终聚类结果。

   * 结果不一定是全局最优的，只能保证局部最优。
   * 对噪声敏感。因为簇的中心是取平均，因此聚类簇很远地方的噪音会导致簇的中心点偏移。
   * 无法解决不规则形状的聚类。
   * 无法处理离散特征，如：`国籍、性别` 等。
7. `k-means` 性质：
   * `k-means` 实际上假设数据是呈现球形分布，实际任务中很少有这种情况。

     与之相比，`GMM` 使用更加一般的数据表示，即高斯分布。

   * `k-means` 假设各个簇的先验概率相同，但是各个簇的数据量可能不均匀。
   * `k-means` 使用欧式距离来衡量样本与各个簇的相似度。这种距离实际上假设数据的各个维度对于相似度的作用是相同的。
   * `k-means` 中，各个样本点只属于与其相似度最高的那个簇，这实际上是`硬` 分簇。 
   * `k-means` 算法的迭代过程实际上等价于`EM` 算法。具体参考`EM` 算法章节。

