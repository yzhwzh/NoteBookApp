# 集成学习误差

1. 考虑一个二类分类问题。设单个样本为 $$\mathbf {\vec x}$$ ，真实类别为 $$y \in \mathcal Y=\{-1,+1\}$$ 。

   假定基类分类器的错误率为 ，即对每个基分类器  有： 。

   * 假设集成学习通过简单投票法结合  个基分类器  。即：若有超过半数的基分类器正确，则集成分类就正确。根据描述，给出集成学习器为： 。
   * 集成学习器预测错误的条件为：  个基分类器预测正确，其中 （即：少于一半的基分类器预测正确），  个基分类器预测错误。

     假设基分类器的错误率相互独立，则集成学习器预测错误的概率为： 。

   * 根据`Hoeffding`不等式有： 。

     可以看出：随着  ， 集成学习器预测错误的概率  。

2. 上述推论有非常关键的一个地方：假设基分类器的错误率相互独立。
   * 实际上个体学习器是为了解决同一个问题训练出来的，而且可能是同一类算法从同一个训练集中产生。

     这样个体学习器的错误率显然不能相互独立。

   * 实际上个体学习器的准确性和多样性本身就存在冲突。
     * 通常个体学习器的准确性很高之后，要增加多样性就需要牺牲准确性。
     * 实际上如何产生并结合”好而不同“的个体学习器就是集成学习研究的核心。

